{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5b776d-e081-4dba-bef0-fb23d6c40f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure the notebook only uses the rtx 3090, and memory growth is allowed\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6722d0d2-6b1b-4b83-8759-dfaf7b0ff774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from collections import Counter\n",
    "from tensorflow.python.client import device_lib\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dfcd18e-6388-4f94-8534-ced2d98e0c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow device: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "#just to make sure, check the gpu tf uses\n",
    "print(\"Tensorflow device: \" + re.search('name: (.+?),', str(device_lib.list_local_devices()[1])).group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35292dd9-cc38-40e4-a09f-96b6945c3936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix random seeds on the cpu and the gpu for reproducability\n",
    "SEED = 6753\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950822ce-a65d-45eb-9a81-801e4544b904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmed\\anaconda3\\envs\\TF 26 for ModelMaker\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#The code works with tensorflow 1 (1.15), but I have tensorflow 2 that I will use as tf1\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0be988-8b38-48cb-8fc9-49477c5332a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions, InceptionV3 \n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sklearn.preprocessing as skp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6914952-8a0c-4b20-aa5a-622365ce0930",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = pd.read_csv('LabelsVA_Feb.csv')\n",
    "specs_dir = glob.glob('Mono/MelSpecs/*.jpeg')\n",
    "test_dir = glob.glob('Mono/TestSpec/*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de8bd5e-9de2-407b-b4c6-2dcad0218091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in test_dir:\n",
    "     spect = load_img(file, target_size=(75, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e264f9a7-ce29-4b57-a280-c85f68fcfc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=75x75 at 0x173C2B3F588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c317cffb-67c2-45f6-9b38-76b01088c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split_files_labels(splitby, csv_file, specs_dir): #new function for splitting-checked-working\n",
    "        \n",
    "    labels = csv_file\n",
    "    filenames_melspecs = []\n",
    "    spects = list()\n",
    "    \n",
    "    for file in specs_dir:\n",
    "        spect = load_img(file, target_size=(75, 75))\n",
    "        spect = preprocess_input(img_to_array(spect))\n",
    "        #spect = img_to_array(spect)\n",
    "        #experimenting with sizes\n",
    "        #spect = tf.image.resize_images(spects, (160, 120))\n",
    "        #need to be a np array for the split\n",
    "        spects.append(spect)\n",
    "\n",
    "    for filename in specs_dir:\n",
    "        filenames_melspecs.append(os.path.splitext(os.path.basename(filename))[0])\n",
    "\n",
    "    df = pd.DataFrame(filenames_melspecs, columns = ['Filename'])\n",
    "    df['V'] = df['Filename'].map(labels.set_index('Filename')['V'])\n",
    "    df['A'] = df['Filename'].map(labels.set_index('Filename')['A'])\n",
    "    Labels = df\n",
    "    Vlabels = Labels.pop('V')\n",
    "    Alabels = Labels.pop('A')\n",
    "    scaler = skp.MinMaxScaler(feature_range=(0, 1))\n",
    "    LabelsV = scaler.fit_transform(np.array(Vlabels).reshape(-1, 1))\n",
    "    LabelsA = scaler.fit_transform(np.array(Alabels).reshape(-1, 1))\n",
    "\n",
    "    def shuffle_in_unison(a, b):\n",
    "        rng_state = np.random.get_state()\n",
    "        np.random.shuffle(a)\n",
    "        np.random.set_state(rng_state)\n",
    "        np.random.shuffle(b)\n",
    "\n",
    "    LabelsAll = np.hstack((LabelsV,LabelsA))\n",
    "    shuffle_in_unison(spects,LabelsAll)\n",
    "\n",
    "    split = int(len(spects)*splitby)\n",
    "    train_data = spects[:split]\n",
    "    train_labels = LabelsAll[:split] \n",
    "    test_data = spects[split:]\n",
    "    test_labels = LabelsAll[split:]\n",
    "        \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228946a6-b412-42b3-8dbe-138660476d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4070a91e-f025-4d82-b657-135e41bfd4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = shuffle_split_files_labels(0.7, csv_file, specs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a53804e-2dd9-4386-979f-127f7b5378db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca0cf111-11a9-4615-a09d-d847059dd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_V,train_labels_A = np.hsplit(train_labels,2)\n",
    "test_labels_V,test_labels_A = np.hsplit(test_labels,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a0092c9c-636c-4a55-831a-24a157483834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_V.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ab866b4-cf41-4542-8c4a-b183e493210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "test_data = np.array(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eae63df-e3db-42f2-9697-87cecc891220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 75, 75, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848cba7-1e6f-4bc8-a34c-762381e36e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#experimenting with sizes\n",
    "#spects = tf.image.resize_images(spects, (160, 120))\n",
    "#need to be a np array for the split\n",
    "#sess = tf.Session()\n",
    "#with sess.as_default():\n",
    "#    spects = spects.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c952f9b-8888-4aed-bdae-f0590a7f87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = tf.image.resize_images(train_data, (160, 120))\n",
    "#test_data = tf.image.resize_images(test_data, (160, 120))\n",
    "#sess = tf.Session()\n",
    "#with sess.as_default():\n",
    "#    train_data = train_data.eval()\n",
    "#    test_data = test_data.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54352f9e-6264-4582-9819-879de79d79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(spects.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e77fe93-da23-415f-9ae7-e59a175e0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27731f82-e8da-42da-bbb0-304694c0aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(spects, labels, test_size=0.25, stratify=labels)\n",
    "#y_train, y_test = tf.keras.utils.to_categorical(y_train, num_classes=3), tf.keras.utils.to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00166f56-0f96-4ad4-a91d-6102c85ad4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(Counter(y_test), Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a5d79e6-d94c-45bd-a649-8432feedd861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahmed\\anaconda3\\envs\\TF 26 for ModelMaker\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\normalization.py:534: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3(include_top=False, input_shape=(75, 75, 3))\n",
    "#model = InceptionV3(include_top=False, input_shape=(640, 480, 3))\n",
    "#retrain completely, or pure fine-tuning with transfer learning? (transfer learning overfits even faster)\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "drop1 = Dropout(0.3)(flat1)\n",
    "class1 = Dense(512, activation='relu')(drop1)  \n",
    "output = Dense(1)(class1)\n",
    "model = Model(inputs=model.inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d389a9cf-8e96-41b3-a641-36dcd75fba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_absolute_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea7b55a2-2549-4e7c-a81a-4ac034c73db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 392 samples, validate on 168 samples\n",
      "Epoch 1/200\n",
      "392/392 [==============================] - ETA: 0s - loss: 0.8589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\anaconda3\\envs\\TF 26 for ModelMaker\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392/392 [==============================] - 6s 16ms/sample - loss: 0.8589 - val_loss: 0.6017\n",
      "Epoch 2/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.2092 - val_loss: 0.5738\n",
      "Epoch 3/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1912 - val_loss: 0.5679\n",
      "Epoch 4/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1895 - val_loss: 0.5293\n",
      "Epoch 5/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1768 - val_loss: 0.6426\n",
      "Epoch 6/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1813 - val_loss: 0.6725\n",
      "Epoch 7/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1648 - val_loss: 0.6890\n",
      "Epoch 8/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1813 - val_loss: 0.4668\n",
      "Epoch 9/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1769 - val_loss: 0.4357\n",
      "Epoch 10/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1783 - val_loss: 0.5649\n",
      "Epoch 11/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1778 - val_loss: 0.4382\n",
      "Epoch 12/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1621 - val_loss: 0.4684\n",
      "Epoch 13/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1614 - val_loss: 0.3035\n",
      "Epoch 14/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1731 - val_loss: 0.4610\n",
      "Epoch 15/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1566 - val_loss: 0.4259\n",
      "Epoch 16/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1628 - val_loss: 0.4752\n",
      "Epoch 17/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1544 - val_loss: 0.3410\n",
      "Epoch 18/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1577 - val_loss: 0.4892\n",
      "Epoch 19/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1672 - val_loss: 0.3629\n",
      "Epoch 20/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1663 - val_loss: 0.3083\n",
      "Epoch 21/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1555 - val_loss: 0.3719\n",
      "Epoch 22/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1580 - val_loss: 0.3273\n",
      "Epoch 23/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1547 - val_loss: 0.4617\n",
      "Epoch 24/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1574 - val_loss: 0.4970\n",
      "Epoch 25/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1540 - val_loss: 0.5619\n",
      "Epoch 26/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1618 - val_loss: 0.4641\n",
      "Epoch 27/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1462 - val_loss: 0.4671\n",
      "Epoch 28/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1522 - val_loss: 0.4120\n",
      "Epoch 29/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1514 - val_loss: 0.2805\n",
      "Epoch 30/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1510 - val_loss: 0.3360\n",
      "Epoch 31/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1583 - val_loss: 0.3830\n",
      "Epoch 32/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1624 - val_loss: 0.3601\n",
      "Epoch 33/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1548 - val_loss: 0.3084\n",
      "Epoch 34/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1475 - val_loss: 0.3401\n",
      "Epoch 35/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1555 - val_loss: 0.3965\n",
      "Epoch 36/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1502 - val_loss: 0.4287\n",
      "Epoch 37/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1456 - val_loss: 0.4110\n",
      "Epoch 38/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1513 - val_loss: 0.3514\n",
      "Epoch 39/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1524 - val_loss: 0.3461\n",
      "Epoch 40/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1546 - val_loss: 0.3710\n",
      "Epoch 41/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1453 - val_loss: 0.4224\n",
      "Epoch 42/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1510 - val_loss: 0.3094\n",
      "Epoch 43/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1468 - val_loss: 0.3806\n",
      "Epoch 44/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1475 - val_loss: 0.3744\n",
      "Epoch 45/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1382 - val_loss: 0.4342\n",
      "Epoch 46/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1506 - val_loss: 0.3507\n",
      "Epoch 47/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1489 - val_loss: 0.2882\n",
      "Epoch 48/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1481 - val_loss: 0.2853\n",
      "Epoch 49/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1447 - val_loss: 0.3418\n",
      "Epoch 50/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1509 - val_loss: 0.3139\n",
      "Epoch 51/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1473 - val_loss: 0.3406\n",
      "Epoch 52/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1467 - val_loss: 0.2890\n",
      "Epoch 53/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1482 - val_loss: 0.3232\n",
      "Epoch 54/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1513 - val_loss: 0.3019\n",
      "Epoch 55/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1440 - val_loss: 0.2983\n",
      "Epoch 56/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1485 - val_loss: 0.2430\n",
      "Epoch 57/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1411 - val_loss: 0.3038\n",
      "Epoch 58/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1459 - val_loss: 0.3554\n",
      "Epoch 59/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1475 - val_loss: 0.3928\n",
      "Epoch 60/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1482 - val_loss: 0.2748\n",
      "Epoch 61/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1432 - val_loss: 0.3613\n",
      "Epoch 62/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1496 - val_loss: 0.2831\n",
      "Epoch 63/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1427 - val_loss: 0.2720\n",
      "Epoch 64/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1451 - val_loss: 0.2659\n",
      "Epoch 65/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1421 - val_loss: 0.3640\n",
      "Epoch 66/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1456 - val_loss: 0.3868\n",
      "Epoch 67/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1484 - val_loss: 0.2629\n",
      "Epoch 68/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1400 - val_loss: 0.3633\n",
      "Epoch 69/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1437 - val_loss: 0.5610\n",
      "Epoch 70/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1449 - val_loss: 0.1927\n",
      "Epoch 71/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1490 - val_loss: 0.2805\n",
      "Epoch 72/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1437 - val_loss: 0.2730\n",
      "Epoch 73/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1436 - val_loss: 0.2364\n",
      "Epoch 74/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1402 - val_loss: 0.2654\n",
      "Epoch 75/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1413 - val_loss: 0.2619\n",
      "Epoch 76/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1397 - val_loss: 0.2585\n",
      "Epoch 77/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1376 - val_loss: 0.2480\n",
      "Epoch 78/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1311 - val_loss: 0.3198\n",
      "Epoch 79/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1417 - val_loss: 0.3214\n",
      "Epoch 80/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1462 - val_loss: 0.3145\n",
      "Epoch 81/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1432 - val_loss: 0.2966\n",
      "Epoch 82/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1443 - val_loss: 0.2593\n",
      "Epoch 83/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1405 - val_loss: 0.2478\n",
      "Epoch 84/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1415 - val_loss: 0.2740\n",
      "Epoch 85/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1407 - val_loss: 0.2686\n",
      "Epoch 86/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1373 - val_loss: 0.2878\n",
      "Epoch 87/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1393 - val_loss: 0.2736\n",
      "Epoch 88/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1398 - val_loss: 0.2506\n",
      "Epoch 89/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1399 - val_loss: 0.2434\n",
      "Epoch 90/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1382 - val_loss: 0.2005\n",
      "Epoch 91/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1373 - val_loss: 0.2404\n",
      "Epoch 92/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1391 - val_loss: 0.2494\n",
      "Epoch 93/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1413 - val_loss: 0.1966\n",
      "Epoch 94/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1397 - val_loss: 0.2705\n",
      "Epoch 95/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1405 - val_loss: 0.2419\n",
      "Epoch 96/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1442 - val_loss: 0.2514\n",
      "Epoch 97/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1365 - val_loss: 0.2286\n",
      "Epoch 98/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1440 - val_loss: 0.2066\n",
      "Epoch 99/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1376 - val_loss: 0.2323\n",
      "Epoch 100/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1391 - val_loss: 0.2504\n",
      "Epoch 101/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1469 - val_loss: 0.2779\n",
      "Epoch 102/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1432 - val_loss: 0.2565\n",
      "Epoch 103/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1398 - val_loss: 0.2460\n",
      "Epoch 104/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1328 - val_loss: 0.3247\n",
      "Epoch 105/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1356 - val_loss: 0.2545\n",
      "Epoch 106/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1436 - val_loss: 0.2798\n",
      "Epoch 107/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1405 - val_loss: 0.2501\n",
      "Epoch 108/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1357 - val_loss: 0.2329\n",
      "Epoch 109/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1409 - val_loss: 0.3047\n",
      "Epoch 110/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1393 - val_loss: 0.3279\n",
      "Epoch 111/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1415 - val_loss: 0.2273\n",
      "Epoch 112/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1383 - val_loss: 0.2351\n",
      "Epoch 113/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1343 - val_loss: 0.2440\n",
      "Epoch 114/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1352 - val_loss: 0.2814\n",
      "Epoch 115/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1422 - val_loss: 0.2234\n",
      "Epoch 116/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1366 - val_loss: 0.1974\n",
      "Epoch 117/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1369 - val_loss: 0.2280\n",
      "Epoch 118/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1375 - val_loss: 0.1936\n",
      "Epoch 119/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1401 - val_loss: 0.2523\n",
      "Epoch 120/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1417 - val_loss: 0.2109\n",
      "Epoch 121/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1323 - val_loss: 0.2119\n",
      "Epoch 122/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1307 - val_loss: 0.2308\n",
      "Epoch 123/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1361 - val_loss: 0.2309\n",
      "Epoch 124/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1340 - val_loss: 0.2109\n",
      "Epoch 125/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1273 - val_loss: 0.2119\n",
      "Epoch 126/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1342 - val_loss: 0.2599\n",
      "Epoch 127/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1356 - val_loss: 0.2454\n",
      "Epoch 128/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1304 - val_loss: 0.2205\n",
      "Epoch 129/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1402 - val_loss: 0.2050\n",
      "Epoch 130/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1297 - val_loss: 0.1957\n",
      "Epoch 131/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1375 - val_loss: 0.1905\n",
      "Epoch 132/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1408 - val_loss: 0.2244\n",
      "Epoch 133/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1339 - val_loss: 0.2310\n",
      "Epoch 134/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1365 - val_loss: 0.1978\n",
      "Epoch 135/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1425 - val_loss: 0.2272\n",
      "Epoch 136/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1369 - val_loss: 0.2217\n",
      "Epoch 137/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1337 - val_loss: 0.2223\n",
      "Epoch 138/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1371 - val_loss: 0.2303\n",
      "Epoch 139/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1305 - val_loss: 0.2436\n",
      "Epoch 140/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1363 - val_loss: 0.1972\n",
      "Epoch 141/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1382 - val_loss: 0.1921\n",
      "Epoch 142/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1359 - val_loss: 0.2278\n",
      "Epoch 143/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1381 - val_loss: 0.2119\n",
      "Epoch 144/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1378 - val_loss: 0.2307\n",
      "Epoch 145/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1387 - val_loss: 0.2304\n",
      "Epoch 146/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1345 - val_loss: 0.2893\n",
      "Epoch 147/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1386 - val_loss: 0.3299\n",
      "Epoch 148/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1330 - val_loss: 0.2790\n",
      "Epoch 149/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1330 - val_loss: 0.2295\n",
      "Epoch 150/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1297 - val_loss: 0.2108\n",
      "Epoch 151/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1290 - val_loss: 0.2503\n",
      "Epoch 152/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1291 - val_loss: 0.2259\n",
      "Epoch 153/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1401 - val_loss: 0.2551\n",
      "Epoch 154/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1332 - val_loss: 0.1946\n",
      "Epoch 155/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1385 - val_loss: 0.2353\n",
      "Epoch 156/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1263 - val_loss: 0.2195\n",
      "Epoch 157/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1343 - val_loss: 0.2383\n",
      "Epoch 158/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1330 - val_loss: 0.3951\n",
      "Epoch 159/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1268 - val_loss: 0.3475\n",
      "Epoch 160/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1376 - val_loss: 0.2191\n",
      "Epoch 161/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1263 - val_loss: 0.2189\n",
      "Epoch 162/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1324 - val_loss: 0.2174\n",
      "Epoch 163/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1332 - val_loss: 0.2853\n",
      "Epoch 164/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1336 - val_loss: 0.3487\n",
      "Epoch 165/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1376 - val_loss: 0.3952\n",
      "Epoch 166/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1329 - val_loss: 0.2649\n",
      "Epoch 167/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1396 - val_loss: 0.2750\n",
      "Epoch 168/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1318 - val_loss: 0.2564\n",
      "Epoch 169/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1363 - val_loss: 0.2365\n",
      "Epoch 170/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1290 - val_loss: 0.2801\n",
      "Epoch 171/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1340 - val_loss: 0.3146\n",
      "Epoch 172/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1341 - val_loss: 0.2708\n",
      "Epoch 173/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1313 - val_loss: 0.2954\n",
      "Epoch 174/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1310 - val_loss: 0.2777\n",
      "Epoch 175/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1383 - val_loss: 0.2833\n",
      "Epoch 176/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1299 - val_loss: 0.2370\n",
      "Epoch 177/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1293 - val_loss: 0.2336\n",
      "Epoch 178/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1349 - val_loss: 0.2445\n",
      "Epoch 179/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1323 - val_loss: 0.2283\n",
      "Epoch 180/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1340 - val_loss: 0.1806\n",
      "Epoch 181/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1363 - val_loss: 0.2464\n",
      "Epoch 182/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1306 - val_loss: 0.2350\n",
      "Epoch 183/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1307 - val_loss: 0.2386\n",
      "Epoch 184/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1321 - val_loss: 0.2352\n",
      "Epoch 185/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1397 - val_loss: 0.2460\n",
      "Epoch 186/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1337 - val_loss: 0.2415\n",
      "Epoch 187/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1238 - val_loss: 0.2662\n",
      "Epoch 188/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1321 - val_loss: 0.2948\n",
      "Epoch 189/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1339 - val_loss: 0.2658\n",
      "Epoch 190/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1262 - val_loss: 0.2887\n",
      "Epoch 191/200\n",
      "392/392 [==============================] - 1s 1ms/sample - loss: 0.1346 - val_loss: 0.2784\n",
      "Epoch 192/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1330 - val_loss: 0.3110\n",
      "Epoch 193/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1323 - val_loss: 0.2068\n",
      "Epoch 194/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1308 - val_loss: 0.2790\n",
      "Epoch 195/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1333 - val_loss: 0.2257\n",
      "Epoch 196/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1302 - val_loss: 0.2797\n",
      "Epoch 197/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1325 - val_loss: 0.2608\n",
      "Epoch 198/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1302 - val_loss: 0.3338\n",
      "Epoch 199/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1282 - val_loss: 0.2242\n",
      "Epoch 200/200\n",
      "392/392 [==============================] - 1s 2ms/sample - loss: 0.1361 - val_loss: 0.2762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x173c35d1cc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,\n",
    "          train_labels_V,\n",
    "          validation_data=(test_data, test_labels_V),\n",
    "          epochs=200,\n",
    "          batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500bede-eb17-42fa-83f6-9a236c2c082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsV = []\n",
    "for i in range(len(test_data)):\n",
    "    predictionsV.append(model.predict(test_data[i:i+1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba8941-a31a-4acc-a301-1c9f138787e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6384a64-c4a9-4cb0-99c8-1c1bbb038bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsV = np.squeeze(predictionsV,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ae55f-5b9d-4431-a390-4b0ed6064631",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c19bfe-a988-430a-8827-9c612b127343",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f87ec-67ec-470e-a208-eb232a52eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a53e17-7f58-4f8d-bd0e-a50b6bb1f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorV = np.absolute(test_labels_V - predictionsV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211969b3-879a-47ee-bc0a-45a10c2dae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346decf-e0c1-4b5b-b0b9-08055340dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_avg_V = np.average(errorV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62c365-22c5-4f08-a8d0-ebdd793e8c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_avg_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15952d8b-0f39-41ec-baba-088f48ad122a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
